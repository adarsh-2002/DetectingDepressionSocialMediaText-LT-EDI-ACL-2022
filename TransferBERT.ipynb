{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "227e3efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U tensorflow-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56e4c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tf-models-official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "777e56a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\anaconda3\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.5.0 and strictly below 2.8.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18bc117c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>Text_data</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_pid_1</td>\n",
       "      <td>Waiting for my mind to have a breakdown once t...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_pid_2</td>\n",
       "      <td>My new years resolution : I'm gonna get my ass...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_pid_3</td>\n",
       "      <td>New year : Somone else Feeling like 2020 will ...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_pid_4</td>\n",
       "      <td>My story I guess : Hi, Im from Germany and my ...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_pid_5</td>\n",
       "      <td>Sat in the dark and cried myself going into th...</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4491</th>\n",
       "      <td>dev_pid_4492</td>\n",
       "      <td>Aren’t we all just tired? : I’ve been depresse...</td>\n",
       "      <td>severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4492</th>\n",
       "      <td>dev_pid_4493</td>\n",
       "      <td>NEED HELP COPING : I had my life pretty much f...</td>\n",
       "      <td>severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4493</th>\n",
       "      <td>dev_pid_4494</td>\n",
       "      <td>Qutting Zoloft Cold Turkey : I was on 75 mg se...</td>\n",
       "      <td>severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4494</th>\n",
       "      <td>dev_pid_4495</td>\n",
       "      <td>Crying : I’m coming off my antidepressants and...</td>\n",
       "      <td>severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4495</th>\n",
       "      <td>dev_pid_4496</td>\n",
       "      <td>Seeking for advice on how to overcome and deal...</td>\n",
       "      <td>severe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7006 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               PID                                          Text_data  \\\n",
       "0      train_pid_1  Waiting for my mind to have a breakdown once t...   \n",
       "1      train_pid_2  My new years resolution : I'm gonna get my ass...   \n",
       "2      train_pid_3  New year : Somone else Feeling like 2020 will ...   \n",
       "3      train_pid_4  My story I guess : Hi, Im from Germany and my ...   \n",
       "4      train_pid_5  Sat in the dark and cried myself going into th...   \n",
       "...            ...                                                ...   \n",
       "4491  dev_pid_4492  Aren’t we all just tired? : I’ve been depresse...   \n",
       "4492  dev_pid_4493  NEED HELP COPING : I had my life pretty much f...   \n",
       "4493  dev_pid_4494  Qutting Zoloft Cold Turkey : I was on 75 mg se...   \n",
       "4494  dev_pid_4495  Crying : I’m coming off my antidepressants and...   \n",
       "4495  dev_pid_4496  Seeking for advice on how to overcome and deal...   \n",
       "\n",
       "         Label  \n",
       "0     moderate  \n",
       "1     moderate  \n",
       "2     moderate  \n",
       "3     moderate  \n",
       "4     moderate  \n",
       "...        ...  \n",
       "4491    severe  \n",
       "4492    severe  \n",
       "4493    severe  \n",
       "4494    severe  \n",
       "4495    severe  \n",
       "\n",
       "[7006 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "col_names = ['PID','Text_data','Label']\n",
    "train_df = pd.read_csv(\"train.tsv\", header=0, sep='\\t', names=col_names)\n",
    "dev_df = pd.read_csv(\"dev_with_labels.tsv\", header=0, sep='\\t', names=col_names)\n",
    "df_combined = pd.concat([train_df, dev_df])\n",
    "df_combined = df_combined.drop_duplicates(subset=['Text_data'])\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5434a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7006, 3), dtype=float32, numpy=\n",
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def reLabel(label):\n",
    "#     if label == 'not depression':\n",
    "#         return 0\n",
    "#     if label == 'moderate':\n",
    "#         return 1\n",
    "#     if label == 'severe':\n",
    "#         return 2\n",
    "\n",
    "# df_combined['Label'] = df_combined['Label'].apply(reLabel)\n",
    "# print(df_combined)\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(df_combined['Label'])\n",
    "df_combined['Label'] = encoder.transform(df_combined['Label'])\n",
    "df_combined\n",
    "\n",
    "label_tf = (tf.one_hot(df_combined['Label'], depth = 3))\n",
    "label_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2f30927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelBinarizer()\n",
    "encoder.fit(df_combined['Label'])\n",
    "encoder.transform(df_combined['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "813dba7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "845.0632315158435\n",
      "509.0\n"
     ]
    }
   ],
   "source": [
    "lengths = []\n",
    "for i in df_combined['Text_data']:\n",
    "    lengths.append(len(i))\n",
    "print(np.average(lengths))\n",
    "print(np.median(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6edd0da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572.3930916357408\n",
      "349.0\n"
     ]
    }
   ],
   "source": [
    "from stop_words import get_stop_words\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "stop_words = list(get_stop_words('en'))         #About 900 stopwords\n",
    "nltk_words = list(stopwords.words('english')) #About 150 stopwords\n",
    "stop_words.extend(nltk_words)\n",
    "\n",
    "filtered_sentence = []\n",
    "\n",
    "for text in df_combined['Text_data']:\n",
    "    text =  ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    filtered_sentence.append(text)\n",
    "\n",
    "df_combined['Text_data'] = filtered_sentence\n",
    "lengths = []\n",
    "for i in df_combined['Text_data']:\n",
    "    lengths.append(len(i))\n",
    "print(np.average(lengths))\n",
    "print(np.median(lengths))\n",
    "\n",
    "train_ds, dev_ds, train_labels, dev_labels = train_test_split(df_combined['Text_data'], df_combined['Label'], test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3444ed81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.6467275916182036, 1: 0.8795982423101067, 2: 3.155855855855856}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "                                        class_weight = \"balanced\",\n",
    "                                        classes = np.unique(df_combined['Label']),\n",
    "                                        y = df_combined['Label']                                                    \n",
    "                                    )\n",
    "class_weights = dict(zip(np.unique(df_combined['Label']), class_weights)),\n",
    "class_weights = class_weights[0]\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "709717c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "train_text = train_ds.to_numpy()\n",
    "# tok = Tokenizer(oov_token='<unk>')\n",
    "# tok.fit_on_texts(train_text)\n",
    "# tok.word_index['<pad>'] = 0\n",
    "# tok.index_word[0] = '<pad>'\n",
    "\n",
    "#train_seqs = tok.texts_to_sequences(train_text)\n",
    "#train_seqs = tf.keras.preprocessing.sequence.pad_sequences(train_seqs, padding='post')\n",
    "\n",
    "train_labels = tf.one_hot(train_labels, depth = 3)\n",
    "\n",
    "valid_text = dev_ds.to_numpy()\n",
    "#valid_seqs = tok.texts_to_sequences(valid_text)\n",
    "#valid_seqs = tf.keras.preprocessing.sequence.pad_sequences(valid_seqs, padding='post')\n",
    "\n",
    "valid_labels = tf.one_hot(dev_labels, depth = 3)\n",
    "\n",
    "class_names = {0:'not depression',1:'moderate',2:'severe'}\n",
    "\n",
    "# CONVERT TO TF DATASETS\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_text,train_labels))\n",
    "valid_ds = tf.data.Dataset.from_tensor_slices((valid_text,valid_labels))\n",
    "\n",
    "train_ds = train_ds.shuffle(100).batch(32)\n",
    "valid_ds = valid_ds.batch(32)\n",
    "\n",
    "#PREFETCH\n",
    "\n",
    "train_ds = train_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "valid_ds = valid_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6f28e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: b\"I'm jealous happy people : I wonder like trust family surrounded friends loved ones. I wonder like mind free violent suicidal thoughts. Do people understand lucky are? I wish I wake without feeling dreadful, I wish I simple things interactions without crippling anxiety. 2020 shitty start far\"\n",
      "Label : [1. 0. 0.]\n",
      "Review: b'A friend? : Anyone bored also lonely. When get lonely go anywhere find someone talk online like texting something. That\\xe2\\x80\\x99s right now. It\\xe2\\x80\\x99s stupid idk. I\\xe2\\x80\\x99m stupid idiot right now. So ignore me. Probs will. I\\xe2\\x80\\x99m good ignored. Sorry. I\\xe2\\x80\\x99m really stupid annoying.'\n",
      "Label : [1. 0. 0.]\n",
      "Review: b'Does anyone else struggle concept self love? I feel like struggle may make hard get better. : [removed]'\n",
      "Label : [0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_ds.take(1):\n",
    "  for i in range(3):\n",
    "    print(f'Review: {text_batch.numpy()[i]}')\n",
    "    label = label_batch\n",
    "    print(f'Label : {label[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbd36254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
     ]
    }
   ],
   "source": [
    "#@title Choose a BERT model to fine-tune\n",
    "\n",
    "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'  #@param [\"bert_en_uncased_L-12_H-768_A-12\", \"bert_en_cased_L-12_H-768_A-12\", \"bert_multi_cased_L-12_H-768_A-12\", \"small_bert/bert_en_uncased_L-2_H-128_A-2\", \"small_bert/bert_en_uncased_L-2_H-256_A-4\", \"small_bert/bert_en_uncased_L-2_H-512_A-8\", \"small_bert/bert_en_uncased_L-2_H-768_A-12\", \"small_bert/bert_en_uncased_L-4_H-128_A-2\", \"small_bert/bert_en_uncased_L-4_H-256_A-4\", \"small_bert/bert_en_uncased_L-4_H-512_A-8\", \"small_bert/bert_en_uncased_L-4_H-768_A-12\", \"small_bert/bert_en_uncased_L-6_H-128_A-2\", \"small_bert/bert_en_uncased_L-6_H-256_A-4\", \"small_bert/bert_en_uncased_L-6_H-512_A-8\", \"small_bert/bert_en_uncased_L-6_H-768_A-12\", \"small_bert/bert_en_uncased_L-8_H-128_A-2\", \"small_bert/bert_en_uncased_L-8_H-256_A-4\", \"small_bert/bert_en_uncased_L-8_H-512_A-8\", \"small_bert/bert_en_uncased_L-8_H-768_A-12\", \"small_bert/bert_en_uncased_L-10_H-128_A-2\", \"small_bert/bert_en_uncased_L-10_H-256_A-4\", \"small_bert/bert_en_uncased_L-10_H-512_A-8\", \"small_bert/bert_en_uncased_L-10_H-768_A-12\", \"small_bert/bert_en_uncased_L-12_H-128_A-2\", \"small_bert/bert_en_uncased_L-12_H-256_A-4\", \"small_bert/bert_en_uncased_L-12_H-512_A-8\", \"small_bert/bert_en_uncased_L-12_H-768_A-12\", \"albert_en_base\", \"electra_small\", \"electra_base\", \"experts_pubmed\", \"experts_wiki_books\", \"talking-heads_base\"]\n",
    "\n",
    "map_name_to_handle = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/google/electra_small/2',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/google/electra_base/2',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
    "}\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "}\n",
    "\n",
    "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1251d029",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3230ef6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys       : ['input_mask', 'input_word_ids', 'input_type_ids']\n",
      "Shape      : (1, 128)\n",
      "Word Ids   : [  101  1045  2572  2061  6517  1998 14777  2157  2085   102     0     0]\n",
      "Input Mask : [1 1 1 1 1 1 1 1 1 1 0 0]\n",
      "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "text_test = ['I am so sad and depressed right now']\n",
    "text_preprocessed = bert_preprocess_model(text_test)\n",
    "\n",
    "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
    "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3075e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d61b86c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Pooled Outputs Shape:(1, 512)\n",
      "Pooled Outputs Values:[-0.2610633   0.96756256  0.14548907  0.5520671   0.54360384  0.3331888\n",
      "  0.9933292  -0.9728479   0.00306453 -0.99994177  0.38466614 -0.9581365 ]\n",
      "Sequence Outputs Shape:(1, 128, 512)\n",
      "Sequence Outputs Values:[[ 0.22679493  0.44570273  1.0670617  ... -2.8421602  -0.40608317\n",
      "   0.7170032 ]\n",
      " [ 0.2935018   0.34215915  0.1386933  ... -2.0460887  -0.6787251\n",
      "  -0.04941279]\n",
      " [-0.14717127  0.5424799  -0.0448623  ... -1.6283281  -1.3944806\n",
      "   0.18597376]\n",
      " ...\n",
      " [ 0.40284657  0.3325398   1.359091   ... -2.279018   -0.22745772\n",
      "   0.5909338 ]\n",
      " [ 0.32569647 -0.31818882  0.00349967 ... -0.8752294   0.6427677\n",
      "   0.6850786 ]\n",
      " [-0.08367953 -0.42930108 -0.08188547 ... -0.8535627   0.5253165\n",
      "   0.54266447]]\n"
     ]
    }
   ],
   "source": [
    "bert_results = bert_model(text_preprocessed)\n",
    "\n",
    "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
    "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
    "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
    "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
    "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f465e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "  encoder_inputs = preprocessing_layer(text_input)\n",
    "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "  outputs = encoder(encoder_inputs)\n",
    "  net = outputs['pooled_output']\n",
    "  net = tf.keras.layers.Dropout(0.1)(net)\n",
    "  net = tf.keras.layers.Dense(3, activation=None, name='classifier')(net)\n",
    "  return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2032503c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.41253728 0.3949361  0.7011579 ]], shape=(1, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "classifier_model = build_classifier_model()\n",
    "bert_raw_result = classifier_model(tf.constant(text_test))\n",
    "print(tf.sigmoid(bert_raw_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b18805a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "import pydot\n",
    "tf.keras.utils.plot_model(classifier_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aba13e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "metrics = tf.metrics.CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e6e9153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b\"I absolutely nothing left live for. : I capable making changes I need move forward, around seek bury further. My mom stole savings ($6k me, maybe $500 her) I car. Without car, I work, (extremely limited public transport area) without job I afford medicine keep functional. I incredibly debilitating ADHD insurance, I human treatment. Just wasteful leech. I use heavy amounts marijuana cope inability live truly help. I friends, mom worst family. I bruised scarred abuse I taken years, I go down. This coronavirus thing gotten thinking, maybe I try get it. Try die, then. It's I want. It's I need.\",\n",
      "       b'Humans : Asked help reddit end getting shat on. I feel like happened constantly work real life. Thought I turn Reddit sometimes, feels too. Suicidal af really trying best treat everyone nice. Sad part is, others ever treat like trash without respect. I\\xe2\\x80\\x99m trying kind, hell people darn mean',\n",
      "       b'Should known : Just something looks like gonna alright, E.g finances looking good offering hope finding new beginning, rubbish I endured 60+ years, heading south. Yeah known.',\n",
      "       b\"The end seems closer usual. : Years clinical depression thought survival skills I use normal days, yet extreme still reach terms panic sadness. Can I delete I tried three times already? There's sadness, family I care honestly, one main thoughts keeps alive. The sadness I always lived came back doubled strength, notes describe end, ironic smile I provide. &amp;#x200B; And I am, writing notes, thoughts coming faster I analyze, world I lost wanted to, people I care anymore. If people still care people carrying pain family I have. Only people I still write message to. Please give rest, pain I feeling years, countless pills hide pain, suicide I relate to, I'm feeling wines, brain, head, emotions. &amp;#x200B; I wish I get rid emotions live life is, learned already I cannot. The pain always coming back ot's me, before. It's kinda soft comfortable, knowing time coming, person care seeing stars. &amp;#x200B; My time coming, regardless irrelevant time is. &amp;#x200B; My monster came again, I ready.\",\n",
      "       b\"I'm ruining life : I everything: friends, mom, girlfriend study well, something seems off. I satisfied life happy. Yeah, I feel good sometimes, I'm happy. There's always thought, I better, I deserve life. People care me, reach hands me, I reach back. There's many dark thoughts head I think I continue like I'm gonna lose everything everyone. Please help me.\",\n",
      "       b'i\\xe2\\x80\\x99m quitting strictly vegan don\\xe2\\x80\\x99t energy it\\xe2\\x80\\x99s small step : feel like i\\xe2\\x80\\x99m recognising like certain amount energy function time can\\xe2\\x80\\x99t good things want like actively vegan help people brain like less exhausted hecked don\\xe2\\x80\\x99t know makes sense feels really big thing makes want cry it\\xe2\\x80\\x99s first time i\\xe2\\x80\\x99ve considered like it\\xe2\\x80\\x99s made feel something quite prominent felt like sharing aaaah thank reading guys',\n",
      "       b'Affordable access online therapy Depression : Grouport powerful new resource offers quality mental health care comfort home. Grouport provides online group therapy delivered expert therapists multitude mental health challenges. Group members share condition meet weekly, showing one another alone, empowering succeed therapy journeys. Grouport affordable, accessible device, provide skills, strength, support needed lead better life. [https://grouporttherapy.com/](https://grouporttherapy.com/)',\n",
      "       b'\"Suicide permanent solution temporary problem\"-an idiot : My dad used tell I hate it. What mental health never improves? What permanent. I\\'ve dealing GAD, OCD, Depression 7 years I recently developed agoraphobia. It\\'s fucking getting better me. Every year mental health gets worse. Im So fucking exhausted. I dont even friends help cope. I\\'m alone I hate life.',\n",
      "       b'knew it. : care, hate fucking people.',\n",
      "       b\"The time I'm relaxed, content okay life I'm high. Waking sober reality massive bummer. : [removed]\",\n",
      "       b'\"When Prozac longer helps\" : [removed]',\n",
      "       b\"How I stop self destructive? : Seriously switch button I press, fuck it? It matter I focus on, I always false sense ambition makes take point world start crumbling front me. My weight, lifestyle, financial status, relationships (sexual platonic), things I'm supposed control over, everything always goes downhill sometime. I'm loss I guess I need life taken away me.\",\n",
      "       b'Does anyone else feel like they\\xe2\\x80\\x99re constant state depression due current world issues? : [removed]',\n",
      "       b\"Exercises (not sport) : I found exercises today. I done them! I have. But I? I mean, yesterday I unable leave bed even go play. I have. I didn't. I bad. Maybe I now? No. Too little time. They'd come badly. But better them, it? I know.\",\n",
      "       b'Coming end : No one really really understand I gone! Does life actually mean something. What I even put earth for? To suffer???? Because I doing. Since I 12 I felt like shit. 18 I feel even worse. I never fit anyone still can\\xe2\\x80\\x99t. All I sit room 24/7 job, can\\xe2\\x80\\x99t drive, friends waiting over. Certain death really frighten anymore. I getting comfortable. It helps knowing IS way shit. Just don\\xe2\\x80\\x99t know right time. I know one day I really crack I prepared it. I surrounded fake people don\\xe2\\x80\\x99t care. And I\\xe2\\x80\\x99m tired it. I don\\xe2\\x80\\x99t even cry anymore I write these. I used feel calm. I want make sure I decide end this. I want certain people know much meant rest know much I hated deep deep down.',\n",
      "       b'supposed kill today : [removed]',\n",
      "       b'Anyone tried electroconvulsive therapy? I want opinions please : Apparently it\\xe2\\x80\\x99s efficient used meds don\\xe2\\x80\\x99t work, 70% chances success. Those objective facts, I want hear people actually tried it.',\n",
      "       b'A friend? : Anyone bored also lonely. When get lonely go anywhere find someone talk online like texting something. That\\xe2\\x80\\x99s right now. It\\xe2\\x80\\x99s stupid idk. I\\xe2\\x80\\x99m stupid idiot right now. So ignore me. Probs will. I\\xe2\\x80\\x99m good ignored. Sorry. I\\xe2\\x80\\x99m really stupid annoying.',\n",
      "       b'Yeah everyone calls mentally ill psycho, I\\xe2\\x80\\x99m better dead : People hate I make everything worse. I\\xe2\\x80\\x99m better dead',\n",
      "       b'Asking question : Does anybody know anything fun activities place meet new people anything like',\n",
      "       b\"I got bombarded bad news today. I'm barely functioning addict bad news me. : It's dad. This first time life I've ever reached help. I'm stubborn prick thinks fix everything despite numerous vices. I hate asking, anyone like chat? I want worry friends. I'm contemplating suicide coping mechanisms inherently self-destructive..\",\n",
      "       b'Fuck : [removed]',\n",
      "       b'My mom made feel like shit : I\\xe2\\x80\\x99ve felt like complete shit especially last month it\\xe2\\x80\\x99s normally pretty bad month complete shit. Nothing bad happened life I\\xe2\\x80\\x99m fucking sad. I\\xe2\\x80\\x99m sad I can\\xe2\\x80\\x99t get bed I cry sleep think dying. I\\xe2\\x80\\x99m bed listening music day I can\\xe2\\x80\\x99t schoolwork I can\\xe2\\x80\\x99t chores I hardly move. Tonight I told mom it\\xe2\\x80\\x99s hard homework asked I skip school raised voice said I\\xe2\\x80\\x99m even trying I\\xe2\\x80\\x99m phone day I can\\xe2\\x80\\x99t anything else it\\xe2\\x80\\x99s hard I\\xe2\\x80\\x99m fucking mad. She\\xe2\\x80\\x99s fucking therapist told it\\xe2\\x80\\x99s fault I\\xe2\\x80\\x99m trying I it\\xe2\\x80\\x99s impossible. Normally I\\xe2\\x80\\x99d get high fall asleep forget psychiatrist getting blood testing soon I can\\xe2\\x80\\x99t anything cuz I don\\xe2\\x80\\x99t wanna denied meds. I\\xe2\\x80\\x99m mad I\\xe2\\x80\\x99m sad I thought side idek anymore I thought therapist understanding made feel like shit one shittiest time life blaming lazy cuz I\\xe2\\x80\\x99m phone I able stuff I I hurt little bit nothing bad I usually don\\xe2\\x80\\x99t all. I doubt anyone\\xe2\\x80\\x99s gonna read rant',\n",
      "       b'Is bad I hate around family : I hate around family I get uneasy start get irritated. Both dad mom alcoholics physically emotionally abusive past. Now I don\\xe2\\x80\\x99t even talk I it\\xe2\\x80\\x99s robotic tone. I don\\xe2\\x80\\x99t hate parents I sometimes feel bad close I can\\xe2\\x80\\x99t ignore I feel. I don\\xe2\\x80\\x99t enjoy company I want best them. And judge call deadbeat dad I wanna let know I\\xe2\\x80\\x99ve beat wires fist feet hands mouth taped I beat. They also controlling mom always back always hovering I\\xe2\\x80\\x99m kinda annoyed treats like little boy like I can\\xe2\\x80\\x99t nothing .',\n",
      "       b'Why people let die peace? : [removed]',\n",
      "       b'Anyone else feel extreme guilt someone actually cares? : My mum recently figured badly I\\xe2\\x80\\x99m depressed I\\xe2\\x80\\x99ve home holidays. This morning told she\\xe2\\x80\\x99s really worried I can\\xe2\\x80\\x99t stop thinking it. Like I\\xe2\\x80\\x99ve completely ruined perspective I\\xe2\\x80\\x99m wasting time. Even worse, feels like I\\xe2\\x80\\x99m faking someone seems care me. Now I feel even worse dragging mum mental health issues.',\n",
      "       b'Fight : Brotherhood friendship fake',\n",
      "       b'Finally visited Psychiatrist decided whatever says all. : He diagnosed GAD OCD - comfired And prescribed Thiavion 100 mg Tab flex 50 mg Tab Adipizol 5 mg Tab ranol 40 mg Tell anyone tried opinion. I bit scared I want live normal life',\n",
      "       b'Damn... time bad : Everything I mean EVERYTHING feels sk boring. You guys got advice?',\n",
      "       b'I need help : How start loving myself? How improve things do?',\n",
      "       b'F/22 I think I go back therapy medication... : I medication CBT PTSD, depression general anxiety I 20 stopped (even though I much improvement with) I travel abroad study. The last 6 months hell. I way many panic attacks public, depressive episodes even sleepless nights despite successful student. I happy achievements I keep breakdowns affect studying, social life, confidence sports abilities. I don\\xe2\\x80\\x99t want state I I 12, 18 20yrs old. I don\\xe2\\x80\\x99t want continue living constant panicked state I won\\xe2\\x80\\x99t able afford treatment sponsorship. I want ask financial aid mother I don\\xe2\\x80\\x99t want worry I\\xe2\\x80\\x99m relapsing again.',\n",
      "       b'There\\xe2\\x80\\x99s much darkness, I can\\xe2\\x80\\x99t anymore - F26 : Do ever think there\\xe2\\x80\\x99s nothing keep going except you\\xe2\\x80\\x99ll put close family end it? I think that\\xe2\\x80\\x99s thing stopping me. But hand I think they\\xe2\\x80\\x99d better without me. I feel like burden everyone. They\\xe2\\x80\\x99ve told I better I\\xe2\\x80\\x99ve gotten worse. I can\\xe2\\x80\\x99t anymore.'],\n",
      "      dtype=object)>, <tf.Tensor: shape=(32, 3), dtype=float32, numpy=\n",
      "array([[1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 1., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [0., 1., 0.],\n",
      "       [1., 0., 0.],\n",
      "       [0., 0., 1.],\n",
      "       [1., 0., 0.]], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "for i in train_ds.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbe14114",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d3969de",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model.compile(optimizer=optimizer,\n",
    "                         loss=loss,\n",
    "                         metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81f34c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " preprocessing (KerasLayer)     {'input_mask': (Non  0           ['text[0][0]']                   \n",
      "                                e, 128),                                                          \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 128)}                                                      \n",
      "                                                                                                  \n",
      " BERT_encoder (KerasLayer)      {'default': (None,   28763649    ['preprocessing[0][0]',          \n",
      "                                512),                             'preprocessing[0][1]',          \n",
      "                                 'pooled_output': (               'preprocessing[0][2]']          \n",
      "                                None, 512),                                                       \n",
      "                                 'encoder_outputs':                                               \n",
      "                                 [(None, 128, 512),                                               \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 (None, 128, 512)],                                               \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 128, 512)}                                                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 512)          0           ['BERT_encoder[0][5]']           \n",
      "                                                                                                  \n",
      " classifier (Dense)             (None, 3)            1539        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 28,765,188\n",
      "Trainable params: 28,765,187\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a04b90d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Epoch 1/10\n",
      "176/176 [==============================] - 74s 393ms/step - loss: 0.9352 - categorical_accuracy: 0.5614 - val_loss: 0.9015 - val_categorical_accuracy: 0.6006\n",
      "Epoch 2/10\n",
      "176/176 [==============================] - 69s 391ms/step - loss: 0.8191 - categorical_accuracy: 0.6135 - val_loss: 0.8270 - val_categorical_accuracy: 0.6127\n",
      "Epoch 3/10\n",
      "176/176 [==============================] - 69s 392ms/step - loss: 0.7452 - categorical_accuracy: 0.6563 - val_loss: 0.8051 - val_categorical_accuracy: 0.6234\n",
      "Epoch 4/10\n",
      "176/176 [==============================] - 69s 395ms/step - loss: 0.6782 - categorical_accuracy: 0.6975 - val_loss: 0.8396 - val_categorical_accuracy: 0.6113\n",
      "Epoch 5/10\n",
      "176/176 [==============================] - 69s 395ms/step - loss: 0.6024 - categorical_accuracy: 0.7323 - val_loss: 0.9199 - val_categorical_accuracy: 0.6191\n",
      "Epoch 6/10\n",
      "176/176 [==============================] - 69s 391ms/step - loss: 0.5269 - categorical_accuracy: 0.7768 - val_loss: 0.9651 - val_categorical_accuracy: 0.6177\n",
      "Epoch 7/10\n",
      "176/176 [==============================] - 69s 393ms/step - loss: 0.4570 - categorical_accuracy: 0.8128 - val_loss: 1.0152 - val_categorical_accuracy: 0.5956\n",
      "Epoch 8/10\n",
      "176/176 [==============================] - 70s 399ms/step - loss: 0.4018 - categorical_accuracy: 0.8412 - val_loss: 1.0970 - val_categorical_accuracy: 0.5977\n",
      "Epoch 9/10\n",
      "176/176 [==============================] - 71s 401ms/step - loss: 0.3682 - categorical_accuracy: 0.8549 - val_loss: 1.1072 - val_categorical_accuracy: 0.5999\n",
      "Epoch 10/10\n",
      "176/176 [==============================] - 71s 403ms/step - loss: 0.3323 - categorical_accuracy: 0.8762 - val_loss: 1.1224 - val_categorical_accuracy: 0.5949\n"
     ]
    }
   ],
   "source": [
    "print(f'Training model with {tfhub_handle_encoder}')\n",
    "history = classifier_model.fit(x=train_ds,\n",
    "                               validation_data=valid_ds,\n",
    "                               epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c168fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 124). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "classifier_model.save('saved_model/BertCategorical10epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35bc2c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test_data.tsv\", header=0, sep='\\t', names = ['pid', 'Text_data'])\n",
    "\n",
    "filtered_sentence = []\n",
    "\n",
    "for text in test_df['Text_data']:\n",
    "    text =  ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    filtered_sentence.append(text)\n",
    "\n",
    "test_df['Text_data'] = filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919f2b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = tf.sigmoid(classifier_model(tf.constant(test_df['Text_data'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee27ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3005a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label = []\n",
    "\n",
    "for i in results.numpy():\n",
    "    class_label.append(np.argmax(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ca8435",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['class_label'] = class_label\n",
    "test_df['class_label'] = test_df['class_label'].apply(reLabel)\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66da416f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.drop('Text_data', axis=1)\n",
    "test_df.to_csv('predictionsBERT10epochs.tsv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcec649",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
